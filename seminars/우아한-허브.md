## 데이터허브

![image](https://github.com/user-attachments/assets/80e1962f-aa1e-4ce5-989b-fd49f178aa5f)

화면 하나를 구성하기 위해 필요한 데이터들이 많다.
(혜택, 회원, 셀러, 포인트 등등등)

모든 데이터를 가져올 때 관리팀에 문의하고, 데이터 스펙 협의하고, 데이터 전달 방식 협의하고… 이걸 매번 해야했음.
그래서 데이터 시스템을 하나 만들어서, 그 데이터 시스템에 모든 정보가 다 들어가도록.

![image](https://github.com/user-attachments/assets/2daf106a-2587-4a4a-a7d8-e0854b06ad47)

하루에 약 200억 데이터가 적재되고, 분당 700만 요청이 들어온다.
이런 대규모 트래픽 속에서 안정적으로 시스템을 제공하려면?

1. 데이터를 통합한다. 
2. 데이터를 처리하고 
3. 데이터를 저장하고 
4. 마지막으로 데이터를 조회한다. 
5. 1~4 스텝간 네트워크 통신을 하기 때문에 네트워크도 중요한 자원이 된다.

<img width="739" alt="image" src="https://github.com/user-attachments/assets/f80612c1-7922-4b77-8cb4-d1d68a2882d0">

<br>

## 데이터 통합

<img width="739" alt="image" src="https://github.com/user-attachments/assets/4f8813d6-c2bf-408f-8bb8-9a713d977908">

### 카프카에 바로 메세지를 던지지 않고 퍼블리셔 서버를 배치한 이유?

1. 기술 추상화. kafka 가 아니라 다른걸로 대체해도 상관없어짐. 데이터 전송팀은 어디에 하는지가 중요하지 않고, 그냥 “데이터를 흘려보낸다.” 만 신경쓸 수 있음. Kafka 가 장애가 났을 때 consumer 를 패스하고 바로 데이터 처리 스탭으로 넘기는 것도 가능해짐. 
2. 메세지 형상 관리. 퍼블리셔 서버에서 메세지 스팩을 정해서 메세지 스팩 선점권을 가질 수 있음. 
3. 순서보장. 카프카 파티션 특징을 활용해서.

### 카프카 뒤에 리스너를 둔 이유

1. 백 프레셔. 메세지 퍼블리서의 속도를 조절해서 안정적으로 데이터를 처리할 수 있게 도와주는 매커니즘. Kafka 의 concurrency 개수를 지정해서, 메세지 별로 컨슈머가 처리할 스레드 개수를 지정.(최대 파티션 개수) 이를 통제해서 메세지 처리량을 늘릴지 줄일지를 쉽게 결정할 수 있음. 
2. 메세지 재발행. AbstractConsumerSeek… 뭐시꺵이 구현 
3. 컨슘 제어. MessageListenerContainer.start(), stop() 으로 런타임에 컨슘을 통제할 수 있다. 이걸 어드민에 추가해주면 더 편하겠지?!

<br>

## 데이터 처리

태스크 기반의 워크플로우로 처리하고 있다. 유향 비순환 그래프. 모두가 잘 아는 그것.

<br>

## 데이터 저장

<img width="747" alt="image" src="https://github.com/user-attachments/assets/7db7ec94-6aad-44db-854e-4125fced1083">

고가용성을 갖고, 대용량 쓰기 읽기 트래픽을 견디는 성능이 필요함.

대부분 RDB 가 replication 이 적용되어 있지? 고가용성은 이렇게 챙겨냈는데, 대용량 쓰기 읽기 트래픽은 어케 챙김?
**당연히 알겠지만 DB 쪼개서 분산처리, 병렬처리하는게 답임.**

그럼 분산처리는 어케할래? 인덱스가 커지면 DML(CUD) 에 대한 성능 저하가 발생함.

하나의 테이블이 커지는걸 방지하기 위해서 테이블 샤딩을 진행해야함.

분할하는 가장 큰 이유는 인덱스가 나눠지고, 테이블이 2개가 되어서 병렬처리가 좋아짐.

DB 가 1대면 SPOF, scale-up 만 가능하고 쓰기 작업시 병렬 작업이 어려움.

그럼 어디에 저장해야하는지를 누가 알려주는게 좋은가? 이게 고민거리였음.

애플리케이션에? DB 에?

AWS 서비스에 따라 DB 레벨의 샤딩을 지원하지 않는 이슈가 있었음.

지원하면? 그거 사용하고, 지원하지 않으면 애플리케이션 레벨을 활용해야함.

그래서 결국 애플리케이션 레벨에 샤딩을 구현하기로 결정함.

전략은 3가지. Key based, range based, directory based. 여기서 key 랑 directory 2개를 차용함.

key based 로 파티셔닝을 진행하고, 어디 DB 에 넣을지는 lookup 테이블을 준비해두고 파티션 번호당 샤드 DB 를 결정할 수 있도록 함. directory based.

key based 로 끝내지 않고 directory based 까지 거치는 이유? 파티셔닝이 잘 안될까봐. 도메인이 너무 다양하고 데이터 구조가 다 다양해서 파티션을 균등하게 나누기가 어려움. 그래서 2번 거침.

그래도 결국 핫 파티션과 콜드 파티션은 생길 수 밖에 없음. 보통 새벽 시간에 리밸런싱을 진행하긴 하는데, 비용이 크고 소요시간 예측이 어렵다. 이 때는 lookup 테이블을 수정해서 샤드끼리라도 균등하게 핫 파티션을 가져가게끔.

혹은 기존 샤드가 혼자 힘들어한다면(123) 신규 샤드()를 개설해서 싱크(123)를 맞추고, 핫파티션만 남기고 삭제한다.(3) 그럼 기존에 힘들어하던 샤드에 (12) 만 남는다.

그래도 몰리면 결국 뒤지는거 아님?

앞서 설명한 데이터 처리, 데이터 통합에서 백프레셔 처리.

정합성은? 전시 시스템이니까 어느정도 까고 간다.

<br>

## 네트워크

문제점

1. 각 서버별 중복 구현되는 네트워크 통신 코드 
2. 각 서버 환경에 따라 다르게 설정해야하는 JVM 기반 서버 스택

그래서 고민해야했던 것

1. 스키마 버전 관리 
2. 네트워크 패킷 효율화 
3. 환경에 따른 기술 스택 선택

[우아한 RPC 영상 참고하면 좋다.](https://youtu.be/iOoquUhKT5g?feature=shared)

> 근데 사실 영상에서도 큰 설명 없음. 뻥카에 속음 ㅋㅋㅋ

<img width="689" alt="image" src="https://github.com/user-attachments/assets/39450eaf-5793-461e-9e6b-6f36f993d080">
<img width="687" alt="image" src="https://github.com/user-attachments/assets/40e2a7d0-2261-46c7-a1a4-43ec93a83e8e">

각 서버가 각자 스키마를 관리한다면? 대부분 스키마 형상이 달라진다. 호환성과 형상관리가 어려움.

그래서 우아한 RPC 라이브러리를 만들었는데 RPC 는 IDL 을 미리 정하고 주고 받을 수 있기 때문에 문제를 해결할 수 있다. 모듈을 따로 두고 전체 서버가 그걸 의존하도록 해서 일관성 이런거 다 맞췄음

네트워크 패킷 효율화는 어케해야할까? HTTP/1.1 rest API json 많이 사용할텐데,

사이즈, 직렬화 성능 등 문제가 있음.

json 은 데이터가 크면 직렬화 속도가 빠른데 작으면 오래 걸린다.

protostuff 는 작으면 엄청 빠른데 크면 json 보다 훨씬 오래 걸림.

그래서 데이터 특성(사이즈, 구조)에 따라서 라이브러리를 선택하는게 좋다.

우아한 RPC 라이브러리에 어떤 라이브러리로 응답을 받을지 선택할 수 있도록 해두었음.

그래서 서버간 각자 잘 맞는 통신방식을 선택할 수 있었다.

서버 성능에서 가장 큰 차이를 만드는게 스레드 전략이었다.

당연히 논블록킹이 훨씬 빠르고 좋은데, 에러로그 추적 등이 어렵다. 그래서 CUD 에는 블록킹, R 에는 논블록킹 해두었음.
