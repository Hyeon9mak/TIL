## 잘 사용하던 Kafka 옵션을 제거하기 까지

<img width="747" alt="image" src="https://github.com/user-attachments/assets/b509e09a-534a-4941-b870-5dd2862d9261">

- Push, SMS, LMS, MMS, 알림톡, E-Mail, VMS 등 여러가지 채널을 갖고 있다. 
- 메세지 플랫폼은 한달에 2건의 장애를 경험하면서 서비스를 운영하고 있다. 
  - 통신사, FCM 이 43% 
  - 내부 버그가 30% 
  - 벤더사 장애가 17% 
    - 벤더사를 삼중화 해서 대응하고 있음(ㄷㄷ)
  - 그리고 카프카 장애가 10% 
    - 카프카 자체 클러스터도 이중화해서 가용성을 높이고 있음
- 발송이 끝나면 발송 히스토리 테이블에 데이터를 적재해서 모니터링 하고 있다. 
  - 벤더사, 통신사마다의 장애에 대해 모니터링도 하고 있음 
  - 특정 벤더사가 장애 났을 때 빠르게 다른 벤더사로 전환하는 remote config 도 만들어서 운영중임 
- 작년 11월경 장애 대응 시간 최대 4시간 30분까지도 걸렸었음 
  - 특정 파티션에서 rag 이 증가하면서 장애로 인지 
  - 그러나 장애의 정확한 원인은 Kafka Exactly Once

<img width="730" alt="image" src="https://github.com/user-attachments/assets/b0ec699f-b669-48c4-b538-35e7fa8b2d6c">

<br>

### Exactly Once 가 어떤 장점이 있는데?

1. 멱등성. Producer 를 통해서 중복 제거를 시도함. 중복된 메세지 발송을 원천 차단한다. 
2. 트랜잭션 사용도 가능. 메세지를 묶어서 던지므로, producer → consumer 간 원자성을 보장해줄 수 있다. 
   1. 단, 그 단위가 컨슈머 그룹이므로 메세지가 그룹 내부 컨슈머마다 분산되어 전달될 수도 있다. 
   2. 분산된 메세지를 처리하다가 에러가 발생하면 분산되어 있는 하나의 컨슈머 내부에서만 롤백이 진행됨 
   3. 가령 A / BC 가 나뉘어 전달되었을 때 C 에서 장애가 발생하면 B 까지만 롤백

### 그래서, Exactly Once 를 왜 썼는데?

1. API 한번의 호출로 최대 100명에게. 가령 51번째에서 발송이 실패한 경우? 이걸 처리하기가 쉽다. 
2. 메세지 중복 발신을 미연에 방지해줄 수 있다.

### 근데 이 좋은 Exactly Once 를 제거했다. 왜?

인프라 비용이 감소하고 아키텍처가 심플하지만, 플랫폼 유지 비용이 너무 들었다.
Exactly Once 때문에 장애 대응이 너무 어렵고 피곤한 일이었음.

> 인프라 비용이 감소하고 아키텍처가 심플하다. 적정 수준의 중복 방지가 가능. 
> 직접 구현하면 보다 완벽한 중복 방지가 가능하지만, 인프라 비용이 증가하고 아키텍처 복잡도가 크게 증가한다.

이 두가지 기로에서 직접 구현을 선택했다.

### 그럼 중복 메세지 발행을 어떻게 막을까?

프로듀서에서 hash 를 발행하고, 메세지에 hash 를 넣는다. redis 에 hash 를 탐색해서 이미 보낸 기록이 있는지 검사한다.

<img width="724" alt="image" src="https://github.com/user-attachments/assets/e7d99957-f41b-42ab-a73c-f1ed9e49aded">

redis 최대 메모리는? `hash 길이 * 평균 메세지량` 계측하면 된다.

redis 메모리 최대를 사용하면 어떻게 될까? 자체적으로 지원해주는 기능. key eviction 이 발생한다.

- key eviction : 모든 key 에 대해 LRU 알고리즘 기반으로 정리. 
  - key eviction process 에서는 현재 사용중인 메모리가 최대치라면, 중간에 키를 삭제함. 
  - 삭제 과정에서 부하가 걸리고, 레디스 클러스터 전체가 밀리기 시작한다는 단점이 있다.

<br>

## 3배 트래픽을 받아내기 위한 여정

더 적은 수의 파티션으로 더 많은 트래픽을 받아내야 한다는 요구사항이 들어옴.

> “3배 트래픽? 기존에 Kafka 파티션이 720개 였다면, 3배로 늘려서 2,160 개로 만들면 되지 않을까?”

근데 심지어 파티션 개수를 720 개에서 더 줄여야 했음. ㅋㅋ~

### 파티션 수를 증가시키면..

1. 장애 복구 타임이 증가한다. 
2. 커밋 latency 가 증가한다 
3. 리소스 사용량이 당연히 커지고 
4. 이미 늘린 파티션은 줄일 수가 없다.

이렇게 효과는 불확실한데, 비용과 리스크는 커진다. 비가역적인 위험한 상황

<img width="582" alt="image" src="https://github.com/user-attachments/assets/4e98e578-5127-49c2-ac79-52dee9c8b0b1">

일단 아래와 같은 순서대로 처리량 늘리기를 시도한다.

### 1. 아웃라이어 제거

sender → fcm 에서 신기한 형태의 레이턴시가 발생. 특정 시간마다 수 분 이상 레이턴시가 튀고 있었음

fcm 에서 15분 이상 미응답해서 kafka 에서 리밸런싱이 발생함. 타임아웃을 설정해도 똑같음.

application 에 TimeLimiter 를 구현해서, 이 시간이 초과하면 에러로 발생시키고 리밸런싱이 일어나지 않도록 예방함.

### 2. 동시 처리량 증가 시키기

worker 에서 발송하는 부분에 비효율적인 부분이 있어서 대부분 동시 처리량이 딸린다.

굳이 발송 결과를 알고 다음 Push 를 보내야할까?
모두 독립적이고 순서도 그리 중요하지 않은데?

그래서 컨슈머가 메세지 처리 후 커밋하는게 아니라, 일단 브로커한테 받으면 메세지 샌더 모듈에 던져두고 커밋 해버림.

그럼 이제 중요한게 샌더 모듈이 일시적인 재처리를 해줘야함.
샌더에서 메세지 전송중 실패하면 DLQ 에 떨구고, 별도 컨슈머가 이걸 주워서 다시 처리하도록.
무한정 재시도를 할 순 없고 유효시간 등을 설정해두었음.

<img width="648" alt="image" src="https://github.com/user-attachments/assets/ce7c31c3-457d-4099-a379-8395b7ccf36f">

트래픽이 특정 시간에만 팡팡 튀는 문제가 눈에 들어온다.
트래픽 평탄화를 하려면? 역할에 따른 스레드 풀 분리가 필요하다.
원래 샌더 스레드 하나였는데, push 메타 정보 가져오기 / 실제로 샌딩하기 2개로 분리.

트래픽 성격에 따라서도 스레드 풀을 분리했다.
하나로 관리하면 **배치성, 광고성 Push 떄문에 진짜 중요한 실시간성 push 가 밀릴 수 있음.**
배치성 / 광고성 / 실시간성을 분리하고 각자 최적화를 해볼 수 있다.

<img width="708" alt="image" src="https://github.com/user-attachments/assets/30ed2d91-904c-4337-b8f2-02638a98171a">

<img width="517" alt="image" src="https://github.com/user-attachments/assets/ca485b5a-fd2a-4afd-b558-4aadba6af687">

### 불필요한 카프카 요청 제거

생각해보면 카프카 요청 그 자체도 병목이긴해.

<img width="663" alt="image" src="https://github.com/user-attachments/assets/621dd5e0-89f1-4f32-9eaf-81024d877e69">

- 그림 속 라우터 모듈이 꼭 필요할까? 
  - 벤더사 발송 비율을 조정하고, 발송에 필요한 메타 데이터를 획득한다. 
  - 근데 이게 push 메세지에도 필요할까? 어차피 fcm, apn 을 사용하는데? 
- 그래서 걷어내서 동시성 얻어냄. 
  - 그리고 batch listener 를 적용해서 메세지를 한꺼번에 가져와서 한꺼번에 처리 
  - 원래 매 메세지마다 commit 이 발생하는데, 100건이 들어오면 1 commit 에 100건 처리까지 가능.

<img width="650" alt="image" src="https://github.com/user-attachments/assets/cfe6c67c-3172-46b6-a9e7-5851a8defb5e">

<br>

## QnA

Q. FCM 푸시 API 는 최근 배치 API 가 삭제, 배치 API 라고 하지만 내부는 단건 API 여러번 호출로 변경되어 기존 sdk 는 성능 이슈가 심각하여, 커뮤니티에서 많은 문제 제기가 되어, 많은 해외 회사에서는 직접 구현하는 형태로 회피하고 있는데요. 배민은 어떻게 하셨나요?  
A. ㅜㅜ

Q. 레디스 장애시 메시지 발송 정책이 어떻게 될까요? 발송을 하지 않고 레디스 장애 복구를 기다리는걸까요?  
A. 그냥 발송합니다. 중복 발송이라도 하는게 중요하다고 생각

Q. 알림톡 벤더사 삼중화하면 템플릿 관리 어케함?  
A. 자체 어드민에 템플릿 모아서 벤더사끼리 싱크 맞추는 중. 매일매일 배치 돌려서 싱크 맞추고 있음.
완벽한 방법은 딱히 없는듯.
